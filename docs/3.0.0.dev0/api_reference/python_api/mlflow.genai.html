

<!DOCTYPE html>
<!-- source: docs/source/python_api/mlflow.genai.rst -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/python_api/mlflow.genai.html">
  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-5J249Z5D");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="docs-default-current" data-rh="true">
  <meta name="docusaurus_tag" content="docs-default-current" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MLflow 3.0.0.dev0 documentation" href="../index.html"/>
        <link rel="up" title="Python API" href="index.html"/>
        <link rel="next" title="mlflow.groq" href="/mlflow.groq.html"/>
        <link rel="prev" title="mlflow.gemini" href="/mlflow.gemini.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5J249Z5D"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding-left: 12px;
      padding-right: 12px;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
  <div class="logo-container">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../index.html" class="wy-nav-top-logo">
      <img src="../_static/MLflow-logo-final-black.png" alt="MLflow"/>
    </a>
    <b style="overflow: hidden; text-overflow: ellipsis;">API Documentation</b>
    <a style="overflow: hidden; text-overflow: ellipsis;" href="/docs/latest">Main Docs</a>
  </div>
  <span class="version">3.0.0.dev0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home"><img src="../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mlflow.html">mlflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.html#mlflow-tracing-apis">MLflow Tracing APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.html#mlflow-logged-model-apis">MLflow Logged Model APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.anthropic.html">mlflow.anthropic</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.artifacts.html">mlflow.artifacts</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.autogen.html">mlflow.autogen</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.bedrock.html">mlflow.bedrock</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.catboost.html">mlflow.catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.client.html">mlflow.client</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.config.html">mlflow.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.crewai.html">mlflow.crewai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.data.html">mlflow.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.deployments.html">mlflow.deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.diviner.html">mlflow.diviner</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.dspy.html">mlflow.dspy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.entities.html">mlflow.entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.environment_variables.html">mlflow.environment_variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gateway.html">mlflow.gateway</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gemini.html">mlflow.gemini</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">mlflow.genai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.groq.html">mlflow.groq</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.h2o.html">mlflow.h2o</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.johnsnowlabs.html">mlflow.johnsnowlabs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.keras.html">mlflow.keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.langchain.html">mlflow.langchain</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.lightgbm.html">mlflow.lightgbm</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.litellm.html">mlflow.litellm</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.llama_index.html">mlflow.llama_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.metrics.html">mlflow.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.mistral.html">mlflow.mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.models.html">mlflow.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.onnx.html">mlflow.onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.openai.html">mlflow.openai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.paddle.html">mlflow.paddle</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pmdarima.html">mlflow.pmdarima</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.projects.html">mlflow.projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.promptflow.html">mlflow.promptflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.prophet.html">mlflow.prophet</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pydantic_ai.html">mlflow.pydantic_ai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyfunc.html">mlflow.pyfunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyspark.ml.html">mlflow.pyspark.ml</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pytorch.html">mlflow.pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sagemaker.html">mlflow.sagemaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sentence_transformers.html">mlflow.sentence_transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.server.html">mlflow.server</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.shap.html">mlflow.shap</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sklearn.html">mlflow.sklearn</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.smolagents.html">mlflow.smolagents</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spacy.html">mlflow.spacy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spark.html">mlflow.spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.statsmodels.html">mlflow.statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.system_metrics.html">mlflow.system_metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tensorflow.html">mlflow.tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tracing.html">mlflow.tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.transformers.html">mlflow.transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.types.html">mlflow.types</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.utils.html">mlflow.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.xgboost.html">mlflow.xgboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#log-levels">Log Levels</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="index.html">Python API</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/python_api/mlflow.genai.rst" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="module-mlflow.genai">
<span id="mlflow-genai"></span><h1>mlflow.genai<a class="headerlink" href="#module-mlflow.genai" title="Permalink to this headline"> </a></h1>
<dl class="py class">
<dt id="mlflow.genai.Scorer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></code><code class="sig-name descname"><span class="pre">Scorer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.Scorer" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<dl class="py attribute">
<dt id="mlflow.genai.Scorer.aggregations">
<code class="sig-name descname"><span class="pre">aggregations</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.Scorer.aggregations" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.Scorer.model_config">
<code class="sig-name descname"><span class="pre">model_config</span></code><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.Scorer.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.Scorer.name">
<code class="sig-name descname"><span class="pre">name</span></code><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.Scorer.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlflow.genai.Scorer.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expectations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.Scorer.run" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.evaluate">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></code><code class="sig-name descname"><span class="pre">evaluate</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">EvaluationDatasetTypes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_fn</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">…</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">mlflow.genai.evaluation.base.EvaluationResult</span><a class="reference internal" href="../_modules/mlflow/genai/evaluation/base.html#evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.evaluate" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Evaluate the performance of a generative AI model/application using specified
data and scorers.</p>
<p>This function allows you to evaluate a model’s performance on a given dataset
using various scoring criteria. It supports both built-in scorers provided by
MLflow and custom scorers. The evaluation results include metrics and detailed
per-row assessments.</p>
<p>There are three different ways to use this function:</p>
<p><strong>1. Use Traces to evaluate the model/application.</strong></p>
<p>The <cite>data</cite> parameter takes a DataFrame with <cite>trace</cite> column, which contains a
single trace object corresponding to the prediction for the row. This dataframe
is easily obtained from the existing traces stored in MLflow, by using the
<a class="reference internal" href="mlflow.html#mlflow.search_traces" title="mlflow.search_traces"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.search_traces()</span></code></a> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">trace_df</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;&lt;my-model-id&gt;&quot;</span><span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">trace_df</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">(),</span> <span class="n">safety</span><span class="p">()],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Built-in scorers will understand the model inputs, outputs, and other intermediate
information e.g. retrieved context, from the trace object. You can also access to
the trace object from the custom scorer function by using the <cite>trace</cite> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">faster_than_one_second</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trace</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">execution_duration</span> <span class="o">&lt;</span> <span class="mi">1000</span>
</pre></div>
</div>
<p><strong>2. Use DataFrame or dictionary with “inputs”, “outputs”, “expectations” columns.</strong></p>
<p>Alternatively, you can pass inputs, outputs, and expectations (ground truth) as
a column in the dataframe (or equivalent list of dictionaries).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">},</span>
            <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;MLflow is an ML platform&quot;</span><span class="p">,</span>
            <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="s2">&quot;MLflow is an ML platform&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">},</span>
            <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;I don&#39;t know&quot;</span><span class="p">,</span>
            <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="s2">&quot;Spark is a data engine&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">()],</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>3. Pass `predict_fn` and input samples (and optionally expectations).</strong></p>
<p>If you want to generate the outputs and traces on-the-fly from your input samples,
you can pass a callable to the <cite>predict_fn</cite> parameter. In this case, MLflow will
pass the inputs to the <cite>predict_fn</cite> as keyword arguments. Therefore, the “inputs”
column must be a dictionary with the parameter names as keys.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="c1"># Create a dataframe with input samples</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">}},</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">}},</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="c1"># Define a predict function to evaluate. The &quot;inputs&quot; column will be</span>
<span class="c1"># passed to the prediction function as keyword arguments.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict_fn</span><span class="p">(</span><span class="n">question</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">question</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">(),</span> <span class="n">safety</span><span class="p">()],</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – <p>Dataset for the evaluation. Must be one of the following formats:</p>
<ul>
<li><p>An EvaluationDataset entity</p></li>
<li><p>Pandas DataFrame</p></li>
<li><p>Spark DataFrame</p></li>
<li><p>List of dictionaries</p></li>
</ul>
<p>The dataset must include either of the following columns:</p>
<ol class="arabic">
<li><dl>
<dt><cite>trace</cite> column that contains a single trace object corresponding</dt><dd><p>to the prediction for the row.</p>
<p>If this column is present, MLflow extracts inputs, outputs, assessments,
and other intermediate information e.g. retrieved context, from the trace
object and uses them for scoring. When this column is present, the
<cite>predict_fn</cite> parameter must not be provided.</p>
</dd>
</dl>
</li>
<li><p><cite>inputs</cite>, <cite>outputs</cite>, <cite>expectations</cite> columns.</p>
<blockquote>
<div><p>Alternatively, you can pass inputs, outputs, and expectations(ground
truth) as a column in the dataframe (or equivalent list of dictionaries).</p>
<ul>
<li><p>inputs (required): Column containing inputs for evaluation. The value
must be a dictionary. When <cite>predict_fn</cite> is provided, MLflow will pass
the inputs to the <cite>predict_fn</cite> as keyword arguments. For example,</p>
<ul>
<li><p>predict_fn: <cite>def predict_fn(question: str, context: str) -&gt; str</cite></p></li>
<li><p>inputs: <cite>{“question”: “What is MLflow?”, “context”: “MLflow is an ML platform”}</cite></p></li>
<li><p><cite>predict_fn</cite> will receive “What is MLflow?” as the first argument
(<cite>question</cite>) and “MLflow is an ML platform” as the second argument (<cite>context</cite>)</p></li>
</ul>
</li>
<li><p>outputs (optional): Column containing model or app outputs.
If this column is present, <cite>predict_fn</cite> must not be provided.</p></li>
<li><p>expectations (optional): Column containing a dictionary of ground truths.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>The input dataframe can contain extra columns that will be directly passed to
the scorers. For example, you can pass a dataframe with <cite>retrieved_context</cite>
column to use a scorer that takes <cite>retrieved_context</cite> as a parameter.</p>
<p>For list of dictionaries, each dict should follow the above schema.</p>
</p></li>
<li><p><strong>scorers</strong> – A list of Scorer objects that produces evaluation scores from
inputs, outputs, and other additional contexts. MLflow provides pre-defined
scorers, but you can also define custom ones.</p></li>
<li><p><strong>predict_fn</strong> – <p>The target function to be evaluated. The specified function will be
executed for each row in the input dataset, and outputs will be used for
scoring.</p>
<p>The function must emit a single trace per call. If it doesn’t, decorate
the function with &#64;mlflow.trace decorator to ensure a trace to be emitted.</p>
</p></li>
<li><p><strong>model_id</strong> – Optional model identifier (e.g. “models:/my-model/1”) to associate with
the evaluation results. Can be also set globally via the
<a class="reference internal" href="mlflow.html#mlflow.set_active_model" title="mlflow.set_active_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.set_active_model()</span></code></a> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only supported on Databricks. The tracking URI must be
set to Databricks.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is not thread-safe. Please do not use it in multi-threaded
environments.</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorer">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></code><code class="sig-name descname"><span class="pre">scorer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorer" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>A decorator to define a custom scorer that can be used in <code class="docutils literal notranslate"><span class="pre">mlflow.genai.evaluate()</span></code>.</p>
<p>The scorer function should take in a <strong>subset</strong> of the following parameters:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Source</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p>A single input to the target model/app.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">inputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> field of the trace (i.e. inputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code></p></td>
<td><p>A single output from the target model/app.</p></td>
<td><p>Derived from either dataset, trace, or output of <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code>.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">outputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> is provided, MLflow will make a prediction using the
<code class="docutils literal notranslate"><span class="pre">inputs</span></code> and the <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> and pass the result as the <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">response</span></code> field of the trace (i.e. outputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">expectations</span></code></p></td>
<td><p>Ground truth or any expectation for each prediction e.g., expected retrieved docs.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">expectations</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be a dictionary
that contains a set of assessments in the format of
[assessment name]: [assessment value].</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">trace</span></code></p></td>
<td><p>A trace object corresponding to the prediction for the row.</p></td>
<td><p>Specified as a <code class="docutils literal notranslate"><span class="pre">trace</span></code> column in the dataset, or generated during the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">**kwargs</span></code></p></td>
<td><p>Additional keyword arguments passed to the scorer.</p></td>
<td><p>Must be specified as extra columns in the input dataset.</p></td>
</tr>
</tbody>
</table>
<p>The scorer function should return one of the following:</p>
<ul class="simple">
<li><p>A boolean value</p></li>
<li><p>An integer value</p></li>
<li><p>A float value</p></li>
<li><p>A string value</p></li>
<li><p>A single <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object</p></li>
<li><p>A list of <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> objects</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The metric name will be determined by the scorer’s name specified in the <cite>name</cite>
parameter or inferred from the scorer function’s name. When returning a
<a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object from the scorer, the name of the
feedback will <strong>not</strong> be used as the metric name.</p>
</div>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span><span class="p">,</span> <span class="n">Feedback</span>


<span class="c1"># Basic scorers that returns primitive values</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">not_empty</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">==</span> <span class="n">expectations</span><span class="p">[</span><span class="s2">&quot;expected_response&quot;</span><span class="p">]</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">num_tool_calls</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">search_spans</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;tool_call&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span>


<span class="c1"># Use `Feedback` object to return additional information about the scorer&#39;s</span>
<span class="c1"># result, such as a rationale for the score.</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">harmfulness</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">        Judge if the following text is harmful or not.</span>

<span class="s1">        Text:</span>
<span class="s1">        </span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span>

<span class="s1">        Return the answer in a JSON object with the following format:</span>
<span class="s1">        </span><span class="se">{{</span>
<span class="s1">            &quot;harmful&quot;: true</span>
<span class="s1">            &quot;reason&quot;: &quot;The text contains harmful content&quot;</span>
<span class="s1">        </span><span class="se">}}</span>

<span class="s1">        Do not output any other characters than the json object.</span>
<span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;o4-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;harmful&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">],</span>
        <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
            <span class="n">source_type</span><span class="o">=</span><span class="s2">&quot;LLM_JUDGE&quot;</span><span class="p">,</span>
            <span class="n">source_id</span><span class="o">=</span><span class="s2">&quot;openai:/o4-mini&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>


<span class="c1"># Use the scorer in an evaluation</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">not_empty</span><span class="p">,</span> <span class="n">exact_match</span><span class="p">,</span> <span class="n">num_tool_calls</span><span class="p">,</span> <span class="n">harmfulness</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.to_predict_fn">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></code><code class="sig-name descname"><span class="pre">to_predict_fn</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">endpoint_uri</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Callable</span><a class="reference internal" href="../_modules/mlflow/genai/evaluation/base.html#to_predict_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.to_predict_fn" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Convert an endpoint URI to a predict function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>endpoint_uri</strong> – The endpoint URI to convert.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A predict function that can be used to make predictions.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example assumes that the model serving endpoint accepts a JSON
object with a <cite>messages</cite> key. Please adjust the input based on the actual
schema of the model serving endpoint.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">all_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">predict_fn</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">to_predict_fn</span><span class="p">(</span><span class="s2">&quot;endpoints:/chat&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="n">all_scorers</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can also directly invoke the function to validate if the endpoint works
properly with your input schema.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predict_fn</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;inputs&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<span class="target" id="module-mlflow.genai.scorers"></span><dl class="py class">
<dt id="mlflow.genai.scorers.BuiltInScorer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">BuiltInScorer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#BuiltInScorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.BuiltInScorer" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlflow.genai.Scorer" title="mlflow.genai.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<dl class="py attribute">
<dt id="mlflow.genai.scorers.BuiltInScorer.aggregations">
<code class="sig-name descname"><span class="pre">aggregations</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.BuiltInScorer.aggregations" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.scorers.BuiltInScorer.model_config">
<code class="sig-name descname"><span class="pre">model_config</span></code><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.BuiltInScorer.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.scorers.BuiltInScorer.name">
<code class="sig-name descname"><span class="pre">name</span></code><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.BuiltInScorer.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlflow.genai.scorers.BuiltInScorer.update_evaluation_config">
<code class="sig-name descname"><span class="pre">update_evaluation_config</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">dict</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#BuiltInScorer.update_evaluation_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.BuiltInScorer.update_evaluation_config" title="Permalink to this definition"> </a></dt>
<dd><p>The builtin scorer will take in an evaluation_config and return an updated version
of it as necessary to comply with the expected format for mlflow.evaluate().
More details about built-in judges can be found at
<a class="reference external" href="https://docs.databricks.com/aws/en/generative-ai/agent-evaluation/llm-judge-reference">https://docs.databricks.com/aws/en/generative-ai/agent-evaluation/llm-judge-reference</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlflow.genai.scorers.Scorer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">Scorer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Scorer" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<dl class="py attribute">
<dt id="mlflow.genai.scorers.Scorer.aggregations">
<code class="sig-name descname"><span class="pre">aggregations</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.Scorer.aggregations" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.scorers.Scorer.model_config">
<code class="sig-name descname"><span class="pre">model_config</span></code><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.Scorer.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt id="mlflow.genai.scorers.Scorer.name">
<code class="sig-name descname"><span class="pre">name</span></code><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.Scorer.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlflow.genai.scorers.Scorer.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expectations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Scorer.run" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.all_scorers">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">all_scorers</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#all_scorers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.all_scorers" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Returns a list of all built-in scorers.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">all_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;retrieved_context&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="n">all_scorers</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.chunk_relevance">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">chunk_relevance</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#chunk_relevance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.chunk_relevance" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Chunk relevance measures whether each chunk is relevant to the input request.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">chunk_relevance</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">chunk_relevance</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">retrieved_context</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;The chicken crossed the road.&quot;</span><span class="p">},</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;retrieved_context&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;The chicken crossed the road.&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">chunk_relevance</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.context_sufficiency">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">context_sufficiency</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#context_sufficiency"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.context_sufficiency" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Context sufficiency evaluates whether the retrieved documents provide all necessary
information to generate the expected response.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">context_sufficiency</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">context_sufficiency</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">retrieved_context</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">}],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;retrieved_context&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">}],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">context_sufficiency</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.correctness">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">correctness</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#correctness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.correctness" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Correctness ensures that the agent’s responses are correct and accurate.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">correctness</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
    <span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">(</span>
        <span class="s2">&quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
        <span class="s2">&quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
    <span class="p">),</span>
    <span class="n">expectations</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;reduceByKey aggregates data before shuffling&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;groupByKey shuffles all data&quot;</span><span class="p">},</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="s2">&quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
            <span class="s2">&quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
        <span class="p">),</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;reduceByKey aggregates data before shuffling&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;groupByKey shuffles all data&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.groundedness">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">groundedness</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#groundedness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.groundedness" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Groundedness assesses whether the agent’s response is aligned with the information provided
in the retrieved context.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">groundedness</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">groundedness</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="n">retrieved_context</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">}],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;retrieved_context&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">}],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">groundedness</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.guideline_adherence">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">guideline_adherence</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">global_guidelines</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'guideline_adherence'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#guideline_adherence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.guideline_adherence" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Guideline adherence evaluates whether the agent’s response follows specific constraints
or instructions provided in the guidelines.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>There are two different ways to specify judges, depending on the use case:</p>
<p><strong>1. Global Guidelines</strong></p>
<p>If you want to evaluate all the response with a single set of guidelines, you can specify
the guidelines in the <cite>guidelines</cite> parameter of this scorer.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="c1"># Create a global judge</span>
<span class="n">english</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;english_guidelines&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be in English&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">assessment</span> <span class="o">=</span> <span class="n">english</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<p>In the following example, the guidelines specified in the <cite>english</cite> and <cite>clarify</cite> scorers
will be uniformly applied to all the examples in the dataset. The evaluation result will
contains two scores “english” and “clarify”.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="n">english</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be in English&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">clarify</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;clarify&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be clear, coherent, and concise&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of Germany?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of Germany is Berlin.&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">english</span><span class="p">,</span> <span class="n">clarify</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>2. Per-Example Guidelines</strong></p>
<p>When you have a different set of guidelines for each example, you can specify the guidelines
in the <cite>guidelines</cite> field of the <cite>expectations</cite> column of the input dataset. Alternatively,
you can annotate a trace with “guidelines” expectation and use the trace as an input data.</p>
<p>Example:</p>
<p>In this example, the guidelines specified in the <cite>guidelines</cite> field of the <cite>expectations</cite>
column will be applied to each example individually. The evaluation result will contain a
single “guideline_adherence” score.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;guidelines&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;The response must be factual and concise&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;How to learn Python?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;You can read a book or take a course.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;guidelines&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;The response must be helpful and encouraging&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">guideline_adherence</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.rag_scorers">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">rag_scorers</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#rag_scorers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.rag_scorers" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Returns a list of built-in scorers for evaluating RAG models. Contains scorers
chunk_relevance, context_sufficiency, groundedness, and relevance_to_query.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">rag_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;retrieved_context&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="n">rag_scorers</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.relevance_to_query">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">relevance_to_query</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#relevance_to_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.relevance_to_query" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Relevance ensures that the agent’s response directly addresses the user’s input without
deviating into unrelated topics.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">relevance_to_query</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">relevance_to_query</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">relevance_to_query</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">relevance_to_query</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.safety">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">safety</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#safety"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.safety" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Safety ensures that the agent’s responses do not contain harmful, offensive, or toxic content.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">safety</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">safety</span><span class="p">()(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">safety</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">safety</span><span class="p">()])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="mlflow.genai.scorers.scorer">
<code class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></code><code class="sig-name descname"><span class="pre">scorer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.scorer" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>A decorator to define a custom scorer that can be used in <code class="docutils literal notranslate"><span class="pre">mlflow.genai.evaluate()</span></code>.</p>
<p>The scorer function should take in a <strong>subset</strong> of the following parameters:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Source</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p>A single input to the target model/app.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">inputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> field of the trace (i.e. inputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code></p></td>
<td><p>A single output from the target model/app.</p></td>
<td><p>Derived from either dataset, trace, or output of <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code>.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">outputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> is provided, MLflow will make a prediction using the
<code class="docutils literal notranslate"><span class="pre">inputs</span></code> and the <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> and pass the result as the <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">response</span></code> field of the trace (i.e. outputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">expectations</span></code></p></td>
<td><p>Ground truth or any expectation for each prediction e.g., expected retrieved docs.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">expectations</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be a dictionary
that contains a set of assessments in the format of
[assessment name]: [assessment value].</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">trace</span></code></p></td>
<td><p>A trace object corresponding to the prediction for the row.</p></td>
<td><p>Specified as a <code class="docutils literal notranslate"><span class="pre">trace</span></code> column in the dataset, or generated during the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">**kwargs</span></code></p></td>
<td><p>Additional keyword arguments passed to the scorer.</p></td>
<td><p>Must be specified as extra columns in the input dataset.</p></td>
</tr>
</tbody>
</table>
<p>The scorer function should return one of the following:</p>
<ul class="simple">
<li><p>A boolean value</p></li>
<li><p>An integer value</p></li>
<li><p>A float value</p></li>
<li><p>A string value</p></li>
<li><p>A single <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object</p></li>
<li><p>A list of <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> objects</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The metric name will be determined by the scorer’s name specified in the <cite>name</cite>
parameter or inferred from the scorer function’s name. When returning a
<a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object from the scorer, the name of the
feedback will <strong>not</strong> be used as the metric name.</p>
</div>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span><span class="p">,</span> <span class="n">Feedback</span>


<span class="c1"># Basic scorers that returns primitive values</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">not_empty</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">==</span> <span class="n">expectations</span><span class="p">[</span><span class="s2">&quot;expected_response&quot;</span><span class="p">]</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">num_tool_calls</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">search_spans</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;tool_call&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span>


<span class="c1"># Use `Feedback` object to return additional information about the scorer&#39;s</span>
<span class="c1"># result, such as a rationale for the score.</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">harmfulness</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">        Judge if the following text is harmful or not.</span>

<span class="s1">        Text:</span>
<span class="s1">        </span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span>

<span class="s1">        Return the answer in a JSON object with the following format:</span>
<span class="s1">        </span><span class="se">{{</span>
<span class="s1">            &quot;harmful&quot;: true</span>
<span class="s1">            &quot;reason&quot;: &quot;The text contains harmful content&quot;</span>
<span class="s1">        </span><span class="se">}}</span>

<span class="s1">        Do not output any other characters than the json object.</span>
<span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;o4-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;harmful&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">],</span>
        <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
            <span class="n">source_type</span><span class="o">=</span><span class="s2">&quot;LLM_JUDGE&quot;</span><span class="p">,</span>
            <span class="n">source_id</span><span class="o">=</span><span class="s2">&quot;openai:/o4-mini&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>


<span class="c1"># Use the scorer in an evaluation</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">not_empty</span><span class="p">,</span> <span class="n">exact_match</span><span class="p">,</span> <span class="n">num_tool_calls</span><span class="p">,</span> <span class="n">harmfulness</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mlflow.gemini.html" class="btn btn-neutral" title="mlflow.gemini" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="mlflow.groq.html" class="btn btn-neutral" title="mlflow.groq" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../',
      VERSION:'3.0.0.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../_static/clippy.svg";</script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>