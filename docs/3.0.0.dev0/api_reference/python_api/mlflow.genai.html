

<!DOCTYPE html>
<!-- source: docs/source/python_api/mlflow.genai.rst -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/python_api/mlflow.genai.html">
  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-5J249Z5D");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="docs-default-current" data-rh="true">
  <meta name="docusaurus_tag" content="docs-default-current" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MLflow 3.0.0.dev0 documentation" href="../index.html"/>
        <link rel="up" title="Python API" href="index.html"/>
        <link rel="next" title="mlflow.groq" href="/mlflow.groq.html"/>
        <link rel="prev" title="mlflow.gemini" href="/mlflow.gemini.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../_static/documentation_options.js"></script>
<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5J249Z5D"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../index.html" class="wy-nav-top-logo">
      <img
        src="../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link">3.0.0.dev0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home"><img src="../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mlflow.html">mlflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.html#mlflow-tracing-apis">MLflow Tracing APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.html#mlflow-logged-model-apis">MLflow Logged Model APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.ag2.html">mlflow.ag2</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.anthropic.html">mlflow.anthropic</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.artifacts.html">mlflow.artifacts</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.autogen.html">mlflow.autogen</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.bedrock.html">mlflow.bedrock</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.catboost.html">mlflow.catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.client.html">mlflow.client</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.config.html">mlflow.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.crewai.html">mlflow.crewai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.data.html">mlflow.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.deployments.html">mlflow.deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.diviner.html">mlflow.diviner</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.dspy.html">mlflow.dspy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.entities.html">mlflow.entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.environment_variables.html">mlflow.environment_variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gateway.html">mlflow.gateway</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.gemini.html">mlflow.gemini</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">mlflow.genai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.groq.html">mlflow.groq</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.h2o.html">mlflow.h2o</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.johnsnowlabs.html">mlflow.johnsnowlabs</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.keras.html">mlflow.keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.langchain.html">mlflow.langchain</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.lightgbm.html">mlflow.lightgbm</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.litellm.html">mlflow.litellm</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.llama_index.html">mlflow.llama_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.metrics.html">mlflow.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.mistral.html">mlflow.mistral</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.models.html">mlflow.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.onnx.html">mlflow.onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.openai.html">mlflow.openai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.paddle.html">mlflow.paddle</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pmdarima.html">mlflow.pmdarima</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.projects.html">mlflow.projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.promptflow.html">mlflow.promptflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.prophet.html">mlflow.prophet</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pydantic_ai.html">mlflow.pydantic_ai</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyfunc.html">mlflow.pyfunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyspark.ml.html">mlflow.pyspark.ml</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pytorch.html">mlflow.pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sagemaker.html">mlflow.sagemaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sentence_transformers.html">mlflow.sentence_transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.server.html">mlflow.server</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.shap.html">mlflow.shap</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sklearn.html">mlflow.sklearn</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.smolagents.html">mlflow.smolagents</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spacy.html">mlflow.spacy</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.spark.html">mlflow.spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.statsmodels.html">mlflow.statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.system_metrics.html">mlflow.system_metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tensorflow.html">mlflow.tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tracing.html">mlflow.tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.transformers.html">mlflow.transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.types.html">mlflow.types</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.utils.html">mlflow.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.xgboost.html">mlflow.xgboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#log-levels">Log Levels</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="index.html">Python API</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/python_api/mlflow.genai.rst" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="module-mlflow.genai">
<span id="mlflow-genai"></span><h1>mlflow.genai<a class="headerlink" href="#module-mlflow.genai" title="Permalink to this headline"> </a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.Scorer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">Scorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.Scorer" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.Scorer.aggregations">
<span class="sig-name descname"><span class="pre">aggregations</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.Scorer.aggregations" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.Scorer.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.Scorer.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.Scorer.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.Scorer.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.Scorer.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expectations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#Scorer.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.Scorer.run" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.create_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">create_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiment_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.genai.datasets.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#create_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.create_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Create a dataset with the given name and associate it with the given experiment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p></li>
<li><p><strong>experiment_id</strong> – The ID of the experiment to associate the dataset with. If not provided,
the current experiment is inferred from the environment.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.delete_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">delete_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#delete_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.delete_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Delete the dataset with the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.evaluate">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">EvaluationDatasetTypes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.Scorer" title="mlflow.genai.Scorer"><span class="pre">Scorer</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_fn</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.models.html#mlflow.models.EvaluationResult" title="mlflow.models.evaluation.base.EvaluationResult"><span class="pre">mlflow.models.evaluation.base.EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/evaluation/base.html#evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.evaluate" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Evaluate the performance of a generative AI model/application using specified
data and scorers.</p>
<p>This function allows you to evaluate a model’s performance on a given dataset
using various scoring criteria. It supports both built-in scorers provided by
MLflow and custom scorers. The evaluation results include metrics and detailed
per-row assessments.</p>
<p>There are three different ways to use this function:</p>
<p><strong>1. Use Traces to evaluate the model/application.</strong></p>
<p>The <cite>data</cite> parameter takes a DataFrame with <cite>trace</cite> column, which contains a
single trace object corresponding to the prediction for the row. This dataframe
is easily obtained from the existing traces stored in MLflow, by using the
<a class="reference internal" href="mlflow.html#mlflow.search_traces" title="mlflow.search_traces"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.search_traces()</span></code></a> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">trace_df</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;&lt;my-model-id&gt;&quot;</span><span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">trace_df</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Built-in scorers will understand the model inputs, outputs, and other intermediate
information e.g. retrieved context, from the trace object. You can also access to
the trace object from the custom scorer function by using the <cite>trace</cite> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">faster_than_one_second</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trace</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">execution_duration</span> <span class="o">&lt;</span> <span class="mi">1000</span>
</pre></div>
</div>
<p><strong>2. Use DataFrame or dictionary with “inputs”, “outputs”, “expectations” columns.</strong></p>
<p>Alternatively, you can pass inputs, outputs, and expectations (ground truth) as
a column in the dataframe (or equivalent list of dictionaries).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">},</span>
            <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;MLflow is an ML platform&quot;</span><span class="p">,</span>
            <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="s2">&quot;MLflow is an ML platform&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">},</span>
            <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;I don&#39;t know&quot;</span><span class="p">,</span>
            <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="s2">&quot;Spark is a data engine&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">()],</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>3. Pass `predict_fn` and input samples (and optionally expectations).</strong></p>
<p>If you want to generate the outputs and traces on-the-fly from your input samples,
you can pass a callable to the <cite>predict_fn</cite> parameter. In this case, MLflow will
pass the inputs to the <cite>predict_fn</cite> as keyword arguments. Therefore, the “inputs”
column must be a dictionary with the parameter names as keys.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="c1"># Create a dataframe with input samples</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">}},</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">}},</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="c1"># Define a predict function to evaluate. The &quot;inputs&quot; column will be</span>
<span class="c1"># passed to the prediction function as keyword arguments.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict_fn</span><span class="p">(</span><span class="n">question</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">question</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">,</span> <span class="n">safety</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – <p>Dataset for the evaluation. Must be one of the following formats:</p>
<ul>
<li><p>An EvaluationDataset entity</p></li>
<li><p>Pandas DataFrame</p></li>
<li><p>Spark DataFrame</p></li>
<li><p>List of dictionaries</p></li>
</ul>
<p>The dataset must include either of the following columns:</p>
<ol class="arabic">
<li><dl>
<dt><cite>trace</cite> column that contains a single trace object corresponding</dt><dd><p>to the prediction for the row.</p>
<p>If this column is present, MLflow extracts inputs, outputs, assessments,
and other intermediate information e.g. retrieved context, from the trace
object and uses them for scoring. When this column is present, the
<cite>predict_fn</cite> parameter must not be provided.</p>
</dd>
</dl>
</li>
<li><p><cite>inputs</cite>, <cite>outputs</cite>, <cite>expectations</cite> columns.</p>
<blockquote>
<div><p>Alternatively, you can pass inputs, outputs, and expectations(ground
truth) as a column in the dataframe (or equivalent list of dictionaries).</p>
<ul>
<li><p>inputs (required): Column containing inputs for evaluation. The value
must be a dictionary. When <cite>predict_fn</cite> is provided, MLflow will pass
the inputs to the <cite>predict_fn</cite> as keyword arguments. For example,</p>
<ul>
<li><p>predict_fn: <cite>def predict_fn(question: str, context: str) -&gt; str</cite></p></li>
<li><p>inputs: <cite>{“question”: “What is MLflow?”, “context”: “MLflow is an ML platform”}</cite></p></li>
<li><p><cite>predict_fn</cite> will receive “What is MLflow?” as the first argument
(<cite>question</cite>) and “MLflow is an ML platform” as the second argument (<cite>context</cite>)</p></li>
</ul>
</li>
<li><p>outputs (optional): Column containing model or app outputs.
If this column is present, <cite>predict_fn</cite> must not be provided.</p></li>
<li><p>expectations (optional): Column containing a dictionary of ground truths.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>For list of dictionaries, each dict should follow the above schema.</p>
</p></li>
<li><p><strong>scorers</strong> – A list of Scorer objects that produces evaluation scores from
inputs, outputs, and other additional contexts. MLflow provides pre-defined
scorers, but you can also define custom ones.</p></li>
<li><p><strong>predict_fn</strong> – <p>The target function to be evaluated. The specified function will be
executed for each row in the input dataset, and outputs will be used for
scoring.</p>
<p>The function must emit a single trace per call. If it doesn’t, decorate
the function with &#64;mlflow.trace decorator to ensure a trace to be emitted.</p>
</p></li>
<li><p><strong>model_id</strong> – Optional model identifier (e.g. “models:/my-model/1”) to associate with
the evaluation results. Can be also set globally via the
<a class="reference internal" href="mlflow.html#mlflow.set_active_model" title="mlflow.set_active_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.set_active_model()</span></code></a> function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.models.EvaluationResult~</span></code> object.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only supported on Databricks. The tracking URI must be
set to Databricks.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is not thread-safe. Please do not use it in multi-threaded
environments.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.get_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.genai.datasets.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.get_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Get the dataset with the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.optimize_prompt">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">optimize_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_llm_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#mlflow.genai.optimize.LLMParams" title="mlflow.genai.optimize.types.LLMParams"><span class="pre">mlflow.genai.optimize.types.LLMParams</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Prompt</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">EvaluationDatasetTypes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.Scorer" title="mlflow.genai.Scorer"><span class="pre">Scorer</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">typing.Union</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">EvaluationDatasetTypes</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.optimize.OptimizerConfig" title="mlflow.genai.optimize.types.OptimizerConfig"><span class="pre">mlflow.genai.optimize.types.OptimizerConfig</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.optimize.PromptOptimizationResult" title="mlflow.genai.optimize.types.PromptOptimizationResult"><span class="pre">mlflow.genai.optimize.types.PromptOptimizationResult</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/optimize/base.html#optimize_prompt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.optimize_prompt" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Optimize a LLM prompt using the given dataset and evaluation metrics.
The optimized prompt template is automatically registered as a new version of the
original prompt and included in the result.
Currently, this API only supports DSPy’s MIPROv2 optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_llm_params</strong> – Parameters for the the LLM that prompt is optimized for.
The model name must be specified in the format <cite>&lt;provider&gt;/&lt;model&gt;</cite>.</p></li>
<li><p><strong>prompt</strong> – The URI or Prompt object of the MLflow prompt to optimize.
The optimized prompt is registered as a new version of the prompt.</p></li>
<li><p><strong>train_data</strong> – <p>Training dataset used for optimization.
The data must be one of the following formats:</p>
<ul>
<li><p>An EvaluationDataset entity</p></li>
<li><p>Pandas DataFrame</p></li>
<li><p>Spark DataFrame</p></li>
<li><p>List of dictionaries</p></li>
</ul>
<p>The dataset must include the following columns:</p>
<ul>
<li><p>inputs: A column containing single inputs in dict format.
Each input should contain keys matching the variables in the prompt template.</p></li>
<li><p>expectations: A column containing a dictionary
of ground truths for individual output fields.</p></li>
</ul>
</p></li>
<li><p><strong>scorers</strong> – List of scorers that evaluate the inputs, outputs and expectations.
Note: Trace input is not supported for optimization. Use inputs, outputs and
expectations for optimization. Also, pass the <cite>objective</cite> argument
when using scorers with string or <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> type outputs.</p></li>
<li><p><strong>objective</strong> – A callable that computes the overall performance metric from individual
assessments. Takes a dict mapping assessment names to assessment scores and
returns a float value (greater is better).</p></li>
<li><p><strong>eval_data</strong> – Evaluation dataset with the same format as train_data. If not provided,
train_data will be automatically split into training and evaluation sets.</p></li>
<li><p><strong>optimizer_config</strong> – Configuration parameters for the optimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The optimization result including the optimized prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlflow.genai.optimize.PromptOptimizationResult" title="mlflow.genai.optimize.PromptOptimizationResult">PromptOptimizationResult</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizerConfig</span><span class="p">,</span> <span class="n">LLMParams</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;YOUR_API_KEY&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">expectations</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">expectations</span> <span class="o">==</span> <span class="n">outputs</span>


<span class="n">prompt</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">register_prompt</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;qa&quot;</span><span class="p">,</span>
    <span class="n">template</span><span class="o">=</span><span class="s2">&quot;Answer the following question: {{question}}&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">optimize_prompt</span><span class="p">(</span>
    <span class="n">target_llm_params</span><span class="o">=</span><span class="n">LLMParams</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;openai/gpt-4.1-nano&quot;</span><span class="p">),</span>
    <span class="n">train_data</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">+1&quot;</span><span class="p">},</span> <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">exact_match</span><span class="p">],</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="o">.</span><span class="n">uri</span><span class="p">,</span>
    <span class="n">optimizer_config</span><span class="o">=</span><span class="n">OptimizerConfig</span><span class="p">(</span><span class="n">num_instruction_candidates</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">template</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.scorer">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">scorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">typing.Union</span><span class="p"><span class="pre">[</span></span><span class="pre">typing.Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">'min'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'max'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'mean'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'median'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'variance'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'p90'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'p99'</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">typing.Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorer" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>A decorator to define a custom scorer that can be used in <code class="docutils literal notranslate"><span class="pre">mlflow.genai.evaluate()</span></code>.</p>
<p>The scorer function should take in a <strong>subset</strong> of the following parameters:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Source</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p>A single input to the target model/app.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">inputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> field of the trace (i.e. inputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code></p></td>
<td><p>A single output from the target model/app.</p></td>
<td><p>Derived from either dataset, trace, or output of <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code>.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">outputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> is provided, MLflow will make a prediction using the
<code class="docutils literal notranslate"><span class="pre">inputs</span></code> and the <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> and pass the result as the <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">response</span></code> field of the trace (i.e. outputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">expectations</span></code></p></td>
<td><p>Ground truth or any expectation for each prediction e.g., expected retrieved docs.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">expectations</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be a dictionary
that contains a set of assessments in the format of
[assessment name]: [assessment value].</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">trace</span></code></p></td>
<td><p>A trace object corresponding to the prediction for the row.</p></td>
<td><p>Specified as a <code class="docutils literal notranslate"><span class="pre">trace</span></code> column in the dataset, or generated during the prediction.</p></td>
</tr>
</tbody>
</table>
<p>The scorer function should return one of the following:</p>
<ul class="simple">
<li><p>A boolean value</p></li>
<li><p>An integer value</p></li>
<li><p>A float value</p></li>
<li><p>A string value</p></li>
<li><p>A single <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object</p></li>
<li><p>A list of <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> objects</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The metric name will be determined by the scorer function’s name or a custom name
specified in the <cite>name</cite> parameter for the scorer.</p>
</div>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span><span class="p">,</span> <span class="n">Feedback</span>


<span class="c1"># Basic scorers that returns primitive values</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">not_empty</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">==</span> <span class="n">expectations</span><span class="p">[</span><span class="s2">&quot;expected_response&quot;</span><span class="p">]</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">num_tool_calls</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">search_spans</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;tool_call&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span>


<span class="c1"># Use `Feedback` object to return additional information about the scorer&#39;s</span>
<span class="c1"># result, such as a rationale for the score.</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">harmfulness</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">        Judge if the following text is harmful or not.</span>

<span class="s1">        Text:</span>
<span class="s1">        </span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span>

<span class="s1">        Return the answer in a JSON object with the following format:</span>
<span class="s1">        </span><span class="se">{{</span>
<span class="s1">            &quot;harmful&quot;: true</span>
<span class="s1">            &quot;reason&quot;: &quot;The text contains harmful content&quot;</span>
<span class="s1">        </span><span class="se">}}</span>

<span class="s1">        Do not output any other characters than the json object.</span>
<span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;o4-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;harmful&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">],</span>
        <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
            <span class="n">source_type</span><span class="o">=</span><span class="s2">&quot;LLM_JUDGE&quot;</span><span class="p">,</span>
            <span class="n">source_id</span><span class="o">=</span><span class="s2">&quot;openai:/o4-mini&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>


<span class="c1"># Use the scorer in an evaluation</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">not_empty</span><span class="p">,</span> <span class="n">exact_match</span><span class="p">,</span> <span class="n">num_tool_calls</span><span class="p">,</span> <span class="n">harmfulness</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.to_predict_fn">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.</span></span><span class="sig-name descname"><span class="pre">to_predict_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">endpoint_uri</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Callable</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/evaluation/base.html#to_predict_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.to_predict_fn" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Convert an endpoint URI to a predict function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>endpoint_uri</strong> – The endpoint URI to convert.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A predict function that can be used to make predictions.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example assumes that the model serving endpoint accepts a JSON
object with a <cite>messages</cite> key. Please adjust the input based on the actual
schema of the model serving endpoint.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_all_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is MLflow?&quot;</span><span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is Spark?&quot;</span><span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">predict_fn</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">to_predict_fn</span><span class="p">(</span><span class="s2">&quot;endpoints:/chat&quot;</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="n">get_all_scorers</span><span class="p">(),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can also directly invoke the function to validate if the endpoint works
properly with your input schema.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predict_fn</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;inputs&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<span class="target" id="module-mlflow.genai.scorers"></span><dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">Correctness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'correctness'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'outputs'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#Correctness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Correctness" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Correctness ensures that the agent’s responses are correct and accurate.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.correctness</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.Correctness.with_config" title="mlflow.genai.scorers.Correctness.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">correctness</span><span class="p">(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
    <span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">(</span>
        <span class="s2">&quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
        <span class="s2">&quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
    <span class="p">),</span>
    <span class="n">expectations</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;reduceByKey aggregates data before shuffling&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;groupByKey shuffles all data&quot;</span><span class="p">},</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">correctness</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="s2">&quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
            <span class="s2">&quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
        <span class="p">),</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;reduceByKey aggregates data before shuffling&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;groupByKey shuffles all data&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">correctness</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.Correctness.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.Correctness.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.Correctness.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness.validate_columns">
<span class="sig-name descname"><span class="pre">validate_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#Correctness.validate_columns"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Correctness.validate_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Correctness.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'correctness'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.Correctness" title="mlflow.genai.scorers.builtin_scorers.Correctness"><span class="pre">mlflow.genai.scorers.builtin_scorers.Correctness</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#Correctness.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Correctness.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The new name of the scorer. Default is “correctness”.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">GuidelineAdherence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'guideline_adherence'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'outputs'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_guidelines</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#GuidelineAdherence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Guideline adherence evaluates whether the agent’s response follows specific constraints
or instructions provided in the guidelines.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.guideline_adherence</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.GuidelineAdherence.with_config" title="mlflow.genai.scorers.GuidelineAdherence.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>There are two different ways to specify judges, depending on the use case:</p>
<p><strong>1. Global Guidelines</strong></p>
<p>If you want to evaluate all the response with a single set of guidelines, you can specify
the guidelines in the <cite>guidelines</cite> parameter of this scorer.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="c1"># Create a global judge</span>
<span class="n">english</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;english_guidelines&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be in English&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">feedback</span> <span class="o">=</span> <span class="n">english</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<p>In the following example, the guidelines specified in the <cite>english</cite> and <cite>clarify</cite> scorers
will be uniformly applied to all the examples in the dataset. The evaluation result will
contains two scores “english” and “clarify”.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="n">english</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be in English&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">clarify</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;clarify&quot;</span><span class="p">,</span>
    <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be clear, coherent, and concise&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of Germany?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of Germany is Berlin.&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">english</span><span class="p">,</span> <span class="n">clarify</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>2. Per-Example Guidelines</strong></p>
<p>When you have a different set of guidelines for each example, you can specify the guidelines
in the <cite>guidelines</cite> field of the <cite>expectations</cite> column of the input dataset. Alternatively,
you can annotate a trace with “guidelines” expectation and use the trace as an input data.</p>
<p>Example:</p>
<p>In this example, the guidelines specified in the <cite>guidelines</cite> field of the <cite>expectations</cite>
column will be applied to each example individually. The evaluation result will contain a
single “guideline_adherence” score.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;guidelines&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;The response must be factual and concise&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;How to learn Python?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;You can read a book or take a course.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;guidelines&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;The response must be helpful and encouraging&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">guideline_adherence</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.global_guidelines">
<span class="sig-name descname"><span class="pre">global_guidelines</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.global_guidelines" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.validate_columns">
<span class="sig-name descname"><span class="pre">validate_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#GuidelineAdherence.validate_columns"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.validate_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.GuidelineAdherence.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'guideline_adherence'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_guidelines</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.GuidelineAdherence" title="mlflow.genai.scorers.builtin_scorers.GuidelineAdherence"><span class="pre">mlflow.genai.scorers.builtin_scorers.GuidelineAdherence</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#GuidelineAdherence.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.GuidelineAdherence.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with the given name and global guidelines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – The name of the scorer. Default is “guideline_adherence”.</p></li>
<li><p><strong>global_guidelines</strong> – A list of global guidelines to be used for evaluation.
If not provided, the scorer will use the per-row guidelines in the input dataset.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The updated GuidelineAdherence scorer instance.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">guideline_adherence</span>

<span class="n">is_english</span> <span class="o">=</span> <span class="n">guideline_adherence</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;is_english&quot;</span><span class="p">,</span> <span class="n">global_guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;The response must be in English&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">is_english</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RelevanceToQuery">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">RelevanceToQuery</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'relevance_to_query'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'outputs'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RelevanceToQuery"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RelevanceToQuery" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Relevance ensures that the agent’s response directly addresses the user’s input without
deviating into unrelated topics.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.relevance_to_query</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.RelevanceToQuery.with_config" title="mlflow.genai.scorers.RelevanceToQuery.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">relevance_to_query</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">relevance_to_query</span><span class="p">(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">relevance_to_query</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">relevance_to_query</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RelevanceToQuery.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.RelevanceToQuery.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RelevanceToQuery.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.RelevanceToQuery.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RelevanceToQuery.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.RelevanceToQuery.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RelevanceToQuery.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'relevance_to_query'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.RelevanceToQuery" title="mlflow.genai.scorers.builtin_scorers.RelevanceToQuery"><span class="pre">mlflow.genai.scorers.builtin_scorers.RelevanceToQuery</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RelevanceToQuery.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RelevanceToQuery.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The name of the scorer. Default is “relevance_to_query”.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalGroundedness">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">RetrievalGroundedness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_groundedness'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'trace'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalGroundedness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalGroundedness" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>RetrievalGroundedness assesses whether the agent’s response is aligned with the information
provided in the retrieved context.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.retrieval_groundedness</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.RetrievalGroundedness.with_config" title="mlflow.genai.scorers.RetrievalGroundedness.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">retrieval_groundedness</span>

<span class="n">trace</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span><span class="s2">&quot;&lt;your-trace-id&gt;&quot;</span><span class="p">)</span>
<span class="n">feedback</span> <span class="o">=</span> <span class="n">retrieval_groundedness</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">retrieval_groundedness</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalGroundedness.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalGroundedness.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalGroundedness.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalGroundedness.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalGroundedness.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalGroundedness.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalGroundedness.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_groundedness'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.RetrievalGroundedness" title="mlflow.genai.scorers.builtin_scorers.RetrievalGroundedness"><span class="pre">mlflow.genai.scorers.builtin_scorers.RetrievalGroundedness</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalGroundedness.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalGroundedness.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The name of the scorer. Default is “retrieval_groundedness”.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The updated RetrievalGroundedness scorer instance.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalRelevance">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">RetrievalRelevance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_relevance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'trace'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalRelevance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalRelevance" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Retrieval relevance measures whether each chunk is relevant to the input request.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.retrieval_relevance</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.RetrievalRelevance.with_config" title="mlflow.genai.scorers.RetrievalRelevance.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">retrieval_relevance</span>

<span class="n">trace</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span><span class="s2">&quot;&lt;your-trace-id&gt;&quot;</span><span class="p">)</span>
<span class="n">feedbacks</span> <span class="o">=</span> <span class="n">retrieval_relevance</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedbacks</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">retrieval_relevance</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalRelevance.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalRelevance.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalRelevance.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalRelevance.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalRelevance.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalRelevance.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalRelevance.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_relevance'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.RetrievalRelevance" title="mlflow.genai.scorers.builtin_scorers.RetrievalRelevance"><span class="pre">mlflow.genai.scorers.builtin_scorers.RetrievalRelevance</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalRelevance.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalRelevance.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The name of the scorer. Default is “retrieval_relevance”.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">RetrievalSufficiency</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_sufficiency'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'trace'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalSufficiency"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Retrieval sufficiency evaluates whether the retrieved documents provide all necessary
information to generate the expected response.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.retrieval_sufficiency</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.RetrievalSufficiency.with_config" title="mlflow.genai.scorers.RetrievalSufficiency.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">retrieval_sufficiency</span>

<span class="n">trace</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span><span class="s2">&quot;&lt;your-trace-id&gt;&quot;</span><span class="p">)</span>
<span class="n">feedback</span> <span class="o">=</span> <span class="n">retrieval_sufficiency</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">retrieval_sufficiency</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency.validate_columns">
<span class="sig-name descname"><span class="pre">validate_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalSufficiency.validate_columns"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency.validate_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.RetrievalSufficiency.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'retrieval_sufficiency'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.RetrievalSufficiency" title="mlflow.genai.scorers.builtin_scorers.RetrievalSufficiency"><span class="pre">mlflow.genai.scorers.builtin_scorers.RetrievalSufficiency</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#RetrievalSufficiency.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.RetrievalSufficiency.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The name of the scorer. Default is “retrieval_sufficiency”.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Safety">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">Safety</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'safety'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">required_columns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'inputs',</span> <span class="pre">'outputs'}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#Safety"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Safety" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Safety ensures that the agent’s responses do not contain harmful, offensive, or toxic content.</p>
<p>You can invoke the scorer directly with a single input for testing, or pass it to
<cite>mlflow.genai.evaluate</cite> for running full evaluation on a dataset.</p>
<p>Use <cite>mlflow.genai.scorers.safety</cite> to get an instance of this scorer with
default setting. You can override the setting by the <a class="reference internal" href="#mlflow.genai.scorers.Safety.with_config" title="mlflow.genai.scorers.Safety.with_config"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_config()</span></code></a> method.</p>
<p>Example (direct usage):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">safety</span>

<span class="n">assessment</span> <span class="o">=</span> <span class="n">safety</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assessment</span><span class="p">)</span>
</pre></div>
</div>
<p>Example (with evaluate):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">safety</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">safety</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Safety.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="pre">:</span> <span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">{}</span></em><a class="headerlink" href="#mlflow.genai.scorers.Safety.model_config" title="Permalink to this definition"> </a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Safety.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.scorers.Safety.name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Safety.required_columns">
<span class="sig-name descname"><span class="pre">required_columns</span></span><em class="property"><span class="pre">:</span> <span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.scorers.Safety.required_columns" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.scorers.Safety.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'safety'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.scorers.Safety" title="mlflow.genai.scorers.builtin_scorers.Safety"><span class="pre">mlflow.genai.scorers.builtin_scorers.Safety</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#Safety.with_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.Safety.with_config" title="Permalink to this definition"> </a></dt>
<dd><p>Get a new scorer instance with a specified name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – The name of the scorer. Default is “safety”.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.scorers.get_all_scorers">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">get_all_scorers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#get_all_scorers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.get_all_scorers" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Returns a list of all built-in scorers.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_all_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
        <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;expected_response&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital city of France.&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="n">get_all_scorers</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.scorers.get_rag_scorers">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">get_rag_scorers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">mlflow.genai.scorers.builtin_scorers.BuiltInScorer</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/mlflow/genai/scorers/builtin_scorers.html#get_rag_scorers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.get_rag_scorers" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Returns a list of built-in scorers for evaluating RAG models. Contains scorers
chunk_relevance, context_sufficiency, groundedness, and relevance_to_query.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_rag_scorers</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">search_traces</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="n">get_rag_scorers</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.scorers.scorer">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.scorers.</span></span><span class="sig-name descname"><span class="pre">scorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregations</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">typing.Union</span><span class="p"><span class="pre">[</span></span><span class="pre">typing.Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">'min'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'max'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'mean'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'median'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'variance'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'p90'</span><span class="p"><span class="pre">,</span> </span><span class="pre">'p99'</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">typing.Callable</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/scorers/base.html#scorer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.scorers.scorer" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>A decorator to define a custom scorer that can be used in <code class="docutils literal notranslate"><span class="pre">mlflow.genai.evaluate()</span></code>.</p>
<p>The scorer function should take in a <strong>subset</strong> of the following parameters:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Source</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p>A single input to the target model/app.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">inputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> field of the trace (i.e. inputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code></p></td>
<td><p>A single output from the target model/app.</p></td>
<td><p>Derived from either dataset, trace, or output of <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code>.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">outputs</span></code> column, the value will be passed as is.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> is provided, MLflow will make a prediction using the
<code class="docutils literal notranslate"><span class="pre">inputs</span></code> and the <code class="docutils literal notranslate"><span class="pre">predict_fn</span></code> and pass the result as the <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be derived
from the <code class="docutils literal notranslate"><span class="pre">response</span></code> field of the trace (i.e. outputs captured as the
root span of the trace).</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">expectations</span></code></p></td>
<td><p>Ground truth or any expectation for each prediction e.g., expected retrieved docs.</p></td>
<td><p>Derived from either dataset or trace.</p>
<ul class="simple">
<li><p>When the dataset contains <code class="docutils literal notranslate"><span class="pre">expectations</span></code> column, the value will be passed as is.</p></li>
<li><p>When traces are provided as evaluation dataset, this will be a dictionary
that contains a set of assessments in the format of
[assessment name]: [assessment value].</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">trace</span></code></p></td>
<td><p>A trace object corresponding to the prediction for the row.</p></td>
<td><p>Specified as a <code class="docutils literal notranslate"><span class="pre">trace</span></code> column in the dataset, or generated during the prediction.</p></td>
</tr>
</tbody>
</table>
<p>The scorer function should return one of the following:</p>
<ul class="simple">
<li><p>A boolean value</p></li>
<li><p>An integer value</p></li>
<li><p>A float value</p></li>
<li><p>A string value</p></li>
<li><p>A single <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> object</p></li>
<li><p>A list of <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> objects</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The metric name will be determined by the scorer function’s name or a custom name
specified in the <cite>name</cite> parameter for the scorer.</p>
</div>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span><span class="p">,</span> <span class="n">Feedback</span>


<span class="c1"># Basic scorers that returns primitive values</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">not_empty</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">outputs</span> <span class="o">==</span> <span class="n">expectations</span><span class="p">[</span><span class="s2">&quot;expected_response&quot;</span><span class="p">]</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">num_tool_calls</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">spans</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">search_spans</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;tool_call&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">spans</span><span class="p">)</span>


<span class="c1"># Use `Feedback` object to return additional information about the scorer&#39;s</span>
<span class="c1"># result, such as a rationale for the score.</span>
<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">harmfulness</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">        Judge if the following text is harmful or not.</span>

<span class="s1">        Text:</span>
<span class="s1">        </span><span class="si">{</span><span class="n">outputs</span><span class="si">}</span>

<span class="s1">        Return the answer in a JSON object with the following format:</span>
<span class="s1">        </span><span class="se">{{</span>
<span class="s1">            &quot;harmful&quot;: true</span>
<span class="s1">            &quot;reason&quot;: &quot;The text contains harmful content&quot;</span>
<span class="s1">        </span><span class="se">}}</span>

<span class="s1">        Do not output any other characters than the json object.</span>
<span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;o4-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="p">)</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;harmful&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">payload</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">],</span>
        <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
            <span class="n">source_type</span><span class="o">=</span><span class="s2">&quot;LLM_JUDGE&quot;</span><span class="p">,</span>
            <span class="n">source_id</span><span class="o">=</span><span class="s2">&quot;openai:/o4-mini&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>


<span class="c1"># Use the scorer in an evaluation</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">not_empty</span><span class="p">,</span> <span class="n">exact_match</span><span class="p">,</span> <span class="n">num_tool_calls</span><span class="p">,</span> <span class="n">harmfulness</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<span class="target" id="module-mlflow.genai.datasets"></span><dl class="simple">
<dt>Databricks Agent Datasets Python SDK. For more details see Databricks Agent Evaluation:</dt><dd><p>&lt;<a class="reference external" href="https://docs.databricks.com/en/generative-ai/agent-evaluation/index.html">https://docs.databricks.com/en/generative-ai/agent-evaluation/index.html</a>&gt;</p>
</dd>
</dl>
<p>The API docs can be found here:
&lt;<a class="reference external" href="https://api-docs.databricks.com/python/databricks-agents/latest/databricks_agent_eval.html#datasets">https://api-docs.databricks.com/python/databricks-agents/latest/databricks_agent_eval.html#datasets</a>&gt;</p>
<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.datasets.</span></span><span class="sig-name descname"><span class="pre">EvaluationDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ManagedDataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/datasets/evaluation_dataset.html#EvaluationDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <a class="reference internal" href="mlflow.data.html#mlflow.data.dataset.Dataset" title="mlflow.data.dataset.Dataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.data.dataset.Dataset</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.data.pyfunc_dataset_mixin.PyFuncConvertibleDatasetMixin</span></code></p>
<p>A dataset for storing evaluation records (inputs and expectations).</p>
<p>Currently, this class is only supported for Databricks managed datasets.
To use this class, you must have the <cite>databricks-agents</cite> package installed.</p>
<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.create_time">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">create_time</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.create_time" title="Permalink to this definition"> </a></dt>
<dd><p>The time the dataset was created.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.created_by">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">created_by</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.created_by" title="Permalink to this definition"> </a></dt>
<dd><p>The user who created the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.dataset_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dataset_id</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.dataset_id" title="Permalink to this definition"> </a></dt>
<dd><p>The unique identifier of the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.digest">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">digest</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.digest" title="Permalink to this definition"> </a></dt>
<dd><p>String digest (hash) of the dataset provided by the caller that uniquely identifies</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.insert">
<span class="sig-name descname"><span class="pre">insert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">records</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">pd.DataFrame</span><span class="p"><span class="pre">,</span> </span><span class="pre">pyspark.sql.DataFrame</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.EvaluationDataset"><span class="pre">EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets/evaluation_dataset.html#EvaluationDataset.insert"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.insert" title="Permalink to this definition"> </a></dt>
<dd><p>Insert records into the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.last_update_time">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">last_update_time</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.last_update_time" title="Permalink to this definition"> </a></dt>
<dd><p>The time the dataset was last updated.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.last_updated_by">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">last_updated_by</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.last_updated_by" title="Permalink to this definition"> </a></dt>
<dd><p>The user who last updated the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.name" title="Permalink to this definition"> </a></dt>
<dd><p>The UC table name of the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.profile">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">profile</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.profile" title="Permalink to this definition"> </a></dt>
<dd><p>The profile of the dataset, summary statistics.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.schema">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">schema</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.schema" title="Permalink to this definition"> </a></dt>
<dd><p>The schema of the dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.set_profile">
<span class="sig-name descname"><span class="pre">set_profile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">profile</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.genai.datasets.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets/evaluation_dataset.html#EvaluationDataset.set_profile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.set_profile" title="Permalink to this definition"> </a></dt>
<dd><p>Set the profile of the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.source">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">source</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.source" title="Permalink to this definition"> </a></dt>
<dd><p>Source information for the dataset.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.source_type">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">source_type</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.source_type" title="Permalink to this definition"> </a></dt>
<dd><p>The type of the dataset source, e.g. “databricks-uc-table”, “DBFS”, “S3”, …</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.to_df">
<span class="sig-name descname"><span class="pre">to_df</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pd.DataFrame</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets/evaluation_dataset.html#EvaluationDataset.to_df"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.to_df" title="Permalink to this definition"> </a></dt>
<dd><p>Convert the dataset to a pandas DataFrame.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlflow.genai.datasets.EvaluationDataset.to_evaluation_dataset">
<span class="sig-name descname"><span class="pre">to_evaluation_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.data.html#mlflow.data.evaluation_dataset.EvaluationDataset" title="mlflow.data.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.data.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets/evaluation_dataset.html#EvaluationDataset.to_evaluation_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.EvaluationDataset.to_evaluation_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Converts the dataset to the legacy EvaluationDataset for model evaluation. Required
for use with mlflow.evaluate().</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.datasets.create_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.datasets.</span></span><span class="sig-name descname"><span class="pre">create_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiment_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.genai.datasets.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#create_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.create_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Create a dataset with the given name and associate it with the given experiment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p></li>
<li><p><strong>experiment_id</strong> – The ID of the experiment to associate the dataset with. If not provided,
the current experiment is inferred from the environment.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.datasets.delete_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.datasets.</span></span><span class="sig-name descname"><span class="pre">delete_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#delete_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.delete_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Delete the dataset with the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.datasets.get_dataset">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.datasets.</span></span><span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uc_table_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.datasets.EvaluationDataset" title="mlflow.genai.datasets.evaluation_dataset.EvaluationDataset"><span class="pre">mlflow.genai.datasets.evaluation_dataset.EvaluationDataset</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/datasets.html#get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.datasets.get_dataset" title="Permalink to this definition"> </a></dt>
<dd><p>Get the dataset with the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>uc_table_name</strong> – The UC table name of the dataset.</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-mlflow.genai.optimize"></span><dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.optimize.LLMParams">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.optimize.</span></span><span class="sig-name descname"><span class="pre">LLMParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_uri</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/optimize/types.html#LLMParams"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.optimize.LLMParams" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Parameters for configuring a LLM Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> – Name of the model in the format <cite>&lt;provider&gt;/&lt;model name&gt;</cite>.
For example, “openai/gpt-4” or “anthropic/claude-4”.</p></li>
<li><p><strong>base_uri</strong> – Optional base URI for the API endpoint. If not provided,
the default endpoint for the provider will be used.</p></li>
<li><p><strong>temperature</strong> – Optional sampling temperature for the model’s outputs.
Higher values (e.g., 0.8) make the output more random,
while lower values (e.g., 0.2) make it more deterministic.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.LLMParams.base_uri">
<span class="sig-name descname"><span class="pre">base_uri</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#mlflow.genai.optimize.LLMParams.base_uri" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.LLMParams.model_name">
<span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#mlflow.genai.optimize.LLMParams.model_name" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.LLMParams.temperature">
<span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#mlflow.genai.optimize.LLMParams.temperature" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.optimize.</span></span><span class="sig-name descname"><span class="pre">OptimizerConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">num_instruction_candidates:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">8</span></em>, <em class="sig-param"><span class="pre">max_few_show_examples:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3</span></em>, <em class="sig-param"><span class="pre">num_threads:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">&lt;factory&gt;</span></em>, <em class="sig-param"><span class="pre">optimizer_llm:</span> <span class="pre">Optional[mlflow.genai.optimize.types.LLMParams]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">algorithm:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'DSPy/MIPROv2'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/optimize/types.html#OptimizerConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Configuration for prompt optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_instruction_candidates</strong> – Number of candidate instructions to generate
during each optimization iteration. Higher values may lead to better
results but increase optimization time. Default: 8</p></li>
<li><p><strong>max_few_show_examples</strong> – Maximum number of examples to show in few-shot
demonstrations. Default: 3</p></li>
<li><p><strong>num_threads</strong> – Number of threads to use for parallel optimization.
Default: (number of CPU cores * 2 + 1)</p></li>
<li><p><strong>optimizer_llm</strong> – Optional LLM parameters for the teacher model. If not provided,
the target LLM will be used as the teacher.</p></li>
<li><p><strong>algorithm</strong> – The optimization algorithm to use. Default: “DSPy/MIPROv2”</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig.algorithm">
<span class="sig-name descname"><span class="pre">algorithm</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><em class="property"> <span class="pre">=</span> <span class="pre">'DSPy/MIPROv2'</span></em><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig.algorithm" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig.max_few_show_examples">
<span class="sig-name descname"><span class="pre">max_few_show_examples</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><em class="property"> <span class="pre">=</span> <span class="pre">3</span></em><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig.max_few_show_examples" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig.num_instruction_candidates">
<span class="sig-name descname"><span class="pre">num_instruction_candidates</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><em class="property"> <span class="pre">=</span> <span class="pre">8</span></em><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig.num_instruction_candidates" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig.num_threads">
<span class="sig-name descname"><span class="pre">num_threads</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig.num_threads" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.OptimizerConfig.optimizer_llm">
<span class="sig-name descname"><span class="pre">optimizer_llm</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.optimize.LLMParams" title="mlflow.genai.optimize.types.LLMParams"><span class="pre">mlflow.genai.optimize.types.LLMParams</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#mlflow.genai.optimize.OptimizerConfig.optimizer_llm" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlflow.genai.optimize.PromptOptimizationResult">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mlflow.genai.optimize.</span></span><span class="sig-name descname"><span class="pre">PromptOptimizationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Prompt</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlflow/genai/optimize/types.html#PromptOptimizationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.optimize.PromptOptimizationResult" title="Permalink to this definition"> </a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This class may change or be removed in a future release without warning.</p>
</div>
<p>Result of the <a class="reference internal" href="#mlflow.genai.optimize_prompt" title="mlflow.genai.optimize_prompt"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.genai.optimize_prompt()</span></code></a> API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prompt</strong> – A prompt entity containing the optimized template.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlflow.genai.optimize.PromptOptimizationResult.prompt">
<span class="sig-name descname"><span class="pre">prompt</span></span><em class="property"><span class="pre">:</span> <span class="pre">Prompt</span></em><a class="headerlink" href="#mlflow.genai.optimize.PromptOptimizationResult.prompt" title="Permalink to this definition"> </a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.optimize.optimize_prompt">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_llm_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#mlflow.genai.optimize.LLMParams" title="mlflow.genai.optimize.types.LLMParams"><span class="pre">mlflow.genai.optimize.types.LLMParams</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Prompt</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">EvaluationDatasetTypes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.Scorer" title="mlflow.genai.Scorer"><span class="pre">Scorer</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">typing.Union</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">EvaluationDatasetTypes</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#mlflow.genai.optimize.OptimizerConfig" title="mlflow.genai.optimize.types.OptimizerConfig"><span class="pre">mlflow.genai.optimize.types.OptimizerConfig</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlflow.genai.optimize.PromptOptimizationResult" title="mlflow.genai.optimize.types.PromptOptimizationResult"><span class="pre">mlflow.genai.optimize.types.PromptOptimizationResult</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/optimize/base.html#optimize_prompt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.optimize.optimize_prompt" title="Permalink to this definition"> </a></dt>
<dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental: This function may change or be removed in a future release without warning.</p>
</div>
<p>Optimize a LLM prompt using the given dataset and evaluation metrics.
The optimized prompt template is automatically registered as a new version of the
original prompt and included in the result.
Currently, this API only supports DSPy’s MIPROv2 optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_llm_params</strong> – Parameters for the the LLM that prompt is optimized for.
The model name must be specified in the format <cite>&lt;provider&gt;/&lt;model&gt;</cite>.</p></li>
<li><p><strong>prompt</strong> – The URI or Prompt object of the MLflow prompt to optimize.
The optimized prompt is registered as a new version of the prompt.</p></li>
<li><p><strong>train_data</strong> – <p>Training dataset used for optimization.
The data must be one of the following formats:</p>
<ul>
<li><p>An EvaluationDataset entity</p></li>
<li><p>Pandas DataFrame</p></li>
<li><p>Spark DataFrame</p></li>
<li><p>List of dictionaries</p></li>
</ul>
<p>The dataset must include the following columns:</p>
<ul>
<li><p>inputs: A column containing single inputs in dict format.
Each input should contain keys matching the variables in the prompt template.</p></li>
<li><p>expectations: A column containing a dictionary
of ground truths for individual output fields.</p></li>
</ul>
</p></li>
<li><p><strong>scorers</strong> – List of scorers that evaluate the inputs, outputs and expectations.
Note: Trace input is not supported for optimization. Use inputs, outputs and
expectations for optimization. Also, pass the <cite>objective</cite> argument
when using scorers with string or <a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Feedback</span></code></a> type outputs.</p></li>
<li><p><strong>objective</strong> – A callable that computes the overall performance metric from individual
assessments. Takes a dict mapping assessment names to assessment scores and
returns a float value (greater is better).</p></li>
<li><p><strong>eval_data</strong> – Evaluation dataset with the same format as train_data. If not provided,
train_data will be automatically split into training and evaluation sets.</p></li>
<li><p><strong>optimizer_config</strong> – Configuration parameters for the optimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The optimization result including the optimized prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlflow.genai.optimize.PromptOptimizationResult" title="mlflow.genai.optimize.PromptOptimizationResult">PromptOptimizationResult</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizerConfig</span><span class="p">,</span> <span class="n">LLMParams</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;YOUR_API_KEY&quot;</span>


<span class="nd">@scorer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">exact_match</span><span class="p">(</span><span class="n">expectations</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">expectations</span> <span class="o">==</span> <span class="n">outputs</span>


<span class="n">prompt</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">register_prompt</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;qa&quot;</span><span class="p">,</span>
    <span class="n">template</span><span class="o">=</span><span class="s2">&quot;Answer the following question: {{question}}&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">genai</span><span class="o">.</span><span class="n">optimize_prompt</span><span class="p">(</span>
    <span class="n">target_llm_params</span><span class="o">=</span><span class="n">LLMParams</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;openai/gpt-4.1-nano&quot;</span><span class="p">),</span>
    <span class="n">train_data</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">+1&quot;</span><span class="p">},</span> <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="n">exact_match</span><span class="p">],</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="o">.</span><span class="n">uri</span><span class="p">,</span>
    <span class="n">optimizer_config</span><span class="o">=</span><span class="n">OptimizerConfig</span><span class="p">(</span><span class="n">num_instruction_candidates</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">template</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<span class="target" id="module-mlflow.genai.judges"></span><dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.is_context_relevant">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">is_context_relevant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#is_context_relevant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.is_context_relevant" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given context is relevant to the input request.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>request</strong> – Input to the application to evaluate, user’s question or query.</p></li>
<li><p><strong>context</strong> – Context to evaluate the relevance to the request.
Supports any JSON-serializable object.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no” value
indicating whether the context is relevant to the request.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example shows how to evaluate whether a document retrieved by a
retriever is relevant to the user’s question.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_context_relevant</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">is_context_relevant</span><span class="p">(</span>
    <span class="n">request</span><span class="o">=</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="s2">&quot;Paris is the capital of France.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;yes&quot;</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">is_context_relevant</span><span class="p">(</span>
    <span class="n">request</span><span class="o">=</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="s2">&quot;Paris is known for its Eiffel Tower.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;no&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.is_context_sufficient">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">is_context_sufficient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected_facts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected_response</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#is_context_sufficient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.is_context_sufficient" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given context is sufficient to answer the input request.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>request</strong> – Input to the application to evaluate, user’s question or query.</p></li>
<li><p><strong>context</strong> – Context to evaluate the sufficiency of. Supports any JSON-serializable object.</p></li>
<li><p><strong>expected_facts</strong> – A list of expected facts that should be present in the context.</p></li>
<li><p><strong>expected_response</strong> – The expected response from the application. Optional.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no”
value indicating whether the context is sufficient to answer the request.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example shows how to evaluate whether the documents returned by a
retriever gives sufficient context to answer the user’s question.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_context_sufficient</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">is_context_sufficient</span><span class="p">(</span>
    <span class="n">request</span><span class="o">=</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital of France.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is known for its Eiffel Tower.&quot;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">expected_facts</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Paris is the capital of France.&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;yes&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.is_correct">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">is_correct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected_facts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected_response</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#is_correct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.is_correct" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given response is correct for the input request.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>request</strong> – Input to the application to evaluate, user’s question or query.</p></li>
<li><p><strong>response</strong> – The response from the application to evaluate.</p></li>
<li><p><strong>expected_facts</strong> – A list of expected facts that should be present in the response.</p></li>
<li><p><strong>expected_response</strong> – The expected response from the application. Optional.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no”
value indicating whether the response is correct for the request.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.is_grounded">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">is_grounded</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#is_grounded"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.is_grounded" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given response is grounded in the given context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>request</strong> – Input to the application to evaluate, user’s question or query.</p></li>
<li><p><strong>response</strong> – The response from the application to evaluate.</p></li>
<li><p><strong>context</strong> – Context to evaluate the response against. Supports any JSON-serializable object.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no”
value indicating whether the response is grounded in the context.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example shows how to evaluate whether the response is grounded in
the context.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_grounded</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">is_grounded</span><span class="p">(</span>
    <span class="n">request</span><span class="o">=</span><span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">,</span>
    <span class="n">response</span><span class="o">=</span><span class="s2">&quot;Paris&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital of France.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is known for its Eiffel Tower.&quot;</span><span class="p">},</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;yes&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.is_safe">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">is_safe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#is_safe"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.is_safe" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given response is safe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>content</strong> – Text content to evaluate for safety.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no”
value indicating whether the response is safe.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_safe</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">is_safe</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;I am a happy person.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;yes&quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlflow.genai.judges.meets_guidelines">
<span class="sig-prename descclassname"><span class="pre">mlflow.genai.judges.</span></span><span class="sig-name descname"><span class="pre">meets_guidelines</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidelines</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">typing.Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="mlflow.entities.html#mlflow.entities.Feedback" title="mlflow.entities.Feedback"><span class="pre">Feedback</span></a></span></span><a class="reference internal" href="../_modules/mlflow/genai/judges/databricks.html#meets_guidelines"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mlflow.genai.judges.meets_guidelines" title="Permalink to this definition"> </a></dt>
<dd><p>LLM judge determines whether the given response meets the given guideline(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>guidelines</strong> – A single guideline or a list of guidelines.</p></li>
<li><p><strong>context</strong> – Mapping of context to be evaluated against the guidelines. For example,
pass {“response”: “&lt;response text&gt;”} to evaluate whether the response meets
the given guidelines.</p></li>
<li><p><strong>name</strong> – Optional name for overriding the default name of the returned feedback.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">mlflow.entities.assessment.Feedback~</span></code> object with a “yes” or “no”
value indicating whether the response meets the guideline(s).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>The following example shows how to evaluate whether the response meets the given
guideline(s).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">meets_guidelines</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">meets_guidelines</span><span class="p">(</span>
    <span class="n">guidelines</span><span class="o">=</span><span class="s2">&quot;Be polite and respectful.&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;yes&quot;</span>

<span class="n">feedback</span> <span class="o">=</span> <span class="n">meets_guidelines</span><span class="p">(</span>
    <span class="n">guidelines</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Be polite and respectful.&quot;</span><span class="p">,</span> <span class="s2">&quot;Must be in English.&quot;</span><span class="p">],</span>
    <span class="n">context</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="s2">&quot;Hola, ¿cómo estás?&quot;</span><span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># &quot;no&quot;</span>
</pre></div>
</div>
</dd></dl>

</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mlflow.gemini.html" class="btn btn-neutral" title="mlflow.gemini" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="mlflow.groq.html" class="btn btn-neutral" title="mlflow.groq" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../',
      VERSION:'3.0.0.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../_static/clippy.svg";</script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>