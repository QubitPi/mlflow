"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8591],{11470:(e,n,r)=>{r.d(n,{A:()=>j});var l=r(96540),o=r(34164),i=r(23104),t=r(56347),s=r(205),a=r(57485),c=r(31682),d=r(70679);function p(e){return l.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function m(e){const{values:n,children:r}=e;return(0,l.useMemo)((()=>{const e=n??function(e){return p(e).map((({props:{value:e,label:n,attributes:r,default:l}})=>({value:e,label:n,attributes:r,default:l})))}(r);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,r])}function u({value:e,tabValues:n}){return n.some((n=>n.value===e))}function h({queryString:e=!1,groupId:n}){const r=(0,t.W6)(),o=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,a.aZ)(o),(0,l.useCallback)((e=>{if(!o)return;const n=new URLSearchParams(r.location.search);n.set(o,e),r.replace({...r.location,search:n.toString()})}),[o,r])]}function f(e){const{defaultValue:n,queryString:r=!1,groupId:o}=e,i=m(e),[t,a]=(0,l.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:i}))),[c,p]=h({queryString:r,groupId:o}),[f,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[r,o]=(0,d.Dv)(n);return[r,(0,l.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:o}),_=(()=>{const e=c??f;return u({value:e,tabValues:i})?e:null})();(0,s.A)((()=>{_&&a(_)}),[_]);return{selectedValue:t,selectValue:(0,l.useCallback)((e=>{if(!u({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);a(e),p(e),g(e)}),[p,g,i]),tabValues:i}}var g=r(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=r(74848);function w({className:e,block:n,selectedValue:r,selectValue:l,tabValues:t}){const s=[],{blockElementScrollPositionUntilNextRender:a}=(0,i.a_)(),c=e=>{const n=e.currentTarget,o=s.indexOf(n),i=t[o].value;i!==r&&(a(n),l(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const r=s.indexOf(e.currentTarget)+1;n=s[r]??s[0];break}case"ArrowLeft":{const r=s.indexOf(e.currentTarget)-1;n=s[r]??s[s.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},e),children:t.map((({value:e,label:n,attributes:l})=>(0,v.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:e=>{s.push(e)},onKeyDown:d,onClick:c,...l,className:(0,o.A)("tabs__item",_.tabItem,l?.className,{"tabs__item--active":r===e}),children:n??e},e)))})}function y({lazy:e,children:n,selectedValue:r}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find((e=>e.props.value===r));return e?(0,l.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:i.map(((e,n)=>(0,l.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function x(e){const n=f(e);return(0,v.jsxs)("div",{className:(0,o.A)("tabs-container",_.tabList),children:[(0,v.jsx)(w,{...n,...e}),(0,v.jsx)(y,{...n,...e})]})}function j(e){const n=(0,g.A)();return(0,v.jsx)(x,{...e,children:p(e.children)},String(n))}},19365:(e,n,r)=>{r.d(n,{A:()=>t});r(96540);var l=r(34164);const o={tabItem:"tabItem_Ymn6"};var i=r(74848);function t({children:e,hidden:n,className:r}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,l.A)(o.tabItem,r),hidden:n,children:e})}},28453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>s});var l=r(96540);const o={},i=l.createContext(o);function t(e){const n=l.useContext(i);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),l.createElement(i.Provider,{value:n},e.children)}},49374:(e,n,r)=>{r.d(n,{B:()=>s});r(96540);const l=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var o=r(86025),i=r(74848);const t=e=>{const n=e.split(".");for(let r=n.length;r>0;r--){const e=n.slice(0,r).join(".");if(l[e])return e}return null};function s({fn:e,children:n,hash:r}){const s=t(e);if(!s)return(0,i.jsx)(i.Fragment,{children:n});const a=(0,o.Ay)(`/${l[s]}#${r??e}`);return(0,i.jsx)("a",{href:a,target:"_blank",children:n??(0,i.jsxs)("code",{children:[e,"()"]})})}},72714:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>p,contentTitle:()=>d,default:()=>h,frontMatter:()=>c,metadata:()=>l,toc:()=>m});const l=JSON.parse('{"id":"serving/index","title":"MLflow Model Serving","description":"MLflow provides comprehensive model serving capabilities to deploy your machine learning models as REST APIs for real-time inference. Whether you\'re working with MLflow OSS or Databricks Managed MLflow, you can serve models locally, in cloud environments, or through managed endpoints.","source":"@site/docs/genai/serving/index.mdx","sourceDirName":"serving","slug":"/serving/","permalink":"/docs/3.1.3.dev0/genai/serving/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Prompt Engineering UI","permalink":"/docs/3.1.3.dev0/genai/prompt-version-mgmt/prompt-engineering/"},"next":{"title":"Responses Agent","permalink":"/docs/3.1.3.dev0/genai/serving/responses-agent"}}');var o=r(74848),i=r(28453),t=(r(28774),r(11470)),s=r(19365),a=r(49374);const c={},d="MLflow Model Serving",p={},m=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:3},{value:"Serving Options",id:"serving-options",level:2},{value:"MLflow OSS Serving",id:"mlflow-oss-serving",level:3},{value:"Databricks Managed MLflow",id:"databricks-managed-mlflow",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Basic Model Serving",id:"basic-model-serving",level:3},{value:"Making Predictions",id:"making-predictions",level:3},{value:"Architecture",id:"architecture",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Security Considerations",id:"security-considerations",level:3},{value:"Monitoring and Observability",id:"monitoring-and-observability",level:3},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"Next Steps",id:"next-steps",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"mlflow-model-serving",children:"MLflow Model Serving"})}),"\n",(0,o.jsx)(n.p,{children:"MLflow provides comprehensive model serving capabilities to deploy your machine learning models as REST APIs for real-time inference. Whether you're working with MLflow OSS or Databricks Managed MLflow, you can serve models locally, in cloud environments, or through managed endpoints."}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"MLflow serving transforms your trained models into production-ready inference servers that can handle HTTP requests and return predictions. The serving infrastructure supports various deployment patterns, from local development servers to scalable cloud deployments."}),"\n",(0,o.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83d\udd0c REST API Endpoints"}),": Automatic generation of standardized REST endpoints for model inference"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83e\uddec Multiple Model Formats"}),": Support for various ML frameworks through MLflow's flavor system"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83e\udde0 Custom Applications"}),": Build sophisticated serving applications with custom logic and preprocessing"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83d\udcc8 Scalable Deployment"}),": Deploy to various targets including local servers, cloud platforms, and Kubernetes"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83d\uddc2\ufe0f Model Registry Integration"}),": Seamless integration with MLflow Model Registry for version management"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"serving-options",children:"Serving Options"}),"\n",(0,o.jsx)(n.h3,{id:"mlflow-oss-serving",children:"MLflow OSS Serving"}),"\n",(0,o.jsx)(n.p,{children:"MLflow open-source provides several serving options:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Local Serving"}),": Quick deployment for development and testing using ",(0,o.jsx)(a.B,{fn:"mlflow.server.cli",hash:"mlflow-models-serve",children:(0,o.jsx)(n.code,{children:"mlflow models serve"})})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Custom PyFunc Models"}),": Advanced serving with custom preprocessing, postprocessing, and business logic"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Docker Deployment"}),": Containerized serving for consistent deployment across environments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cloud Platform Integration"}),": Deploy to AWS SageMaker, Azure ML, and other cloud services"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"databricks-managed-mlflow",children:"Databricks Managed MLflow"}),"\n",(0,o.jsx)(n.p,{children:"Databricks provides additional managed serving capabilities:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Serving Endpoints"}),": Fully managed, auto-scaling endpoints with built-in monitoring"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Foundation Model APIs"}),": Direct access to foundation models through pay-per-token endpoints"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Advanced Security"}),": Enterprise-grade security with access controls and audit logging"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Real-time Monitoring"}),": Built-in metrics, logging, and performance monitoring"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,o.jsx)(n.h3,{id:"basic-model-serving",children:"Basic Model Serving"}),"\n",(0,o.jsx)(n.p,{children:"For a simple model serving setup:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'# Serve a logged model\nmlflow models serve -m "models:/<model-id>" -p 5000\n\n# Serve a registered model\nmlflow models serve -m "models:/<model-name>/<model-version>" -p 5000\n\n# Serve a model from local path\nmlflow models serve -m ./path/to/model -p 5000\n'})}),"\n",(0,o.jsx)(n.h3,{id:"making-predictions",children:"Making Predictions"}),"\n",(0,o.jsx)(n.p,{children:"Once your model is served, you can make predictions via HTTP requests:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5000/invocations \\\n  -H "Content-Type: application/json" \\\n  -d \'{"inputs": [[1, 2, 3, 4]]}\'\n'})}),"\n",(0,o.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,o.jsx)(n.p,{children:"MLflow serving uses a standardized architecture:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83e\udde0 Model Loading"}),": Models are loaded using their respective MLflow flavors"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83c\udf10 HTTP Server"}),": FastAPI-based server handles incoming requests"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83d\udd04 Prediction Pipeline"}),": Requests are processed through the model's predict method"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"\ud83d\udce6 Response Formatting"}),": Results are returned in standardized JSON format"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Use appropriate hardware resources based on model requirements"}),"\n",(0,o.jsx)(n.li,{children:"Implement request batching for improved throughput"}),"\n",(0,o.jsx)(n.li,{children:"Consider model quantization for faster inference"}),"\n",(0,o.jsx)(n.li,{children:"Monitor memory usage and optimize accordingly"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement proper authentication and authorization"}),"\n",(0,o.jsx)(n.li,{children:"Use HTTPS in production environments"}),"\n",(0,o.jsx)(n.li,{children:"Validate input data to prevent security vulnerabilities"}),"\n",(0,o.jsx)(n.li,{children:"Regularly update dependencies and monitor for security issues"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"monitoring-and-observability",children:"Monitoring and Observability"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Set up comprehensive logging for debugging and auditing"}),"\n",(0,o.jsx)(n.li,{children:"Monitor key metrics like latency, throughput, and error rates"}),"\n",(0,o.jsx)(n.li,{children:"Implement health checks for service reliability"}),"\n",(0,o.jsx)(n.li,{children:"Use distributed tracing for complex serving pipelines"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,o.jsxs)(t.A,{children:[(0,o.jsxs)(s.A,{value:"real-time-inference",label:"Real-time Inference",children:[(0,o.jsx)(n.p,{children:"Serve models for real-time predictions in web applications, mobile apps, or\nmicroservices architectures."}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import requests\nimport json\n\n# Single prediction\ndata = {\n    "dataframe_split": {\n        "columns": ["feature1", "feature2", "feature3"],\n        "data": [[1.0, 2.0, 3.0]],\n    }\n}\n\nresponse = requests.post(\n    "http://localhost:5000/invocations",\n    headers={"Content-Type": "application/json"},\n    data=json.dumps(data),\n)\nprint(response.json())\n'})})]}),(0,o.jsxs)(s.A,{value:"batch-processing",label:"Batch Processing",children:[(0,o.jsx)(n.p,{children:"Use serving endpoints for batch inference on large datasets with controlled\nresource usage."}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, struct\n\n# Parameters\nmodel_name = "YOUR_MODEL_NAME"\nmodel_version = "YOUR_MODEL_VERSION"\ninput_table = "YOUR_INPUT_TABLE_NAME"\noutput_table = "YOUR_OUTPUT_TABLE_NAME"\n\n# Load data\ndf = spark.table(input_table)\n\n# Apply model using Spark UDF\nmodel_uri = f"models:/{model_name}/{model_version}"\npredict_udf = mlflow.pyfunc.spark_udf(spark, model_uri)\n\n# Make predictions\npredictions_df = df.withColumn(\n    "prediction", predict_udf(struct([col(c) for c in df.columns]))\n)\n\n# Save results\npredictions_df.write.mode("overwrite").saveAsTable(output_table)\n'})}),(0,o.jsxs)(n.p,{children:["See ",(0,o.jsx)(n.a,{href:"https://docs.databricks.com/aws/en/large-language-models/ai-query-batch-inference#batch-llm-inference-using-ai_query",children:"Databricks batch inference documentation"})," for built-in batch inference support with AI Functions on a deployed serving endpoint."]})]}),(0,o.jsxs)(s.A,{value:"ab-testing",label:"A/B Testing",children:[(0,o.jsx)(n.p,{children:"Deploy multiple model versions simultaneously to compare performance and\ngradually roll out improvements."}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nimport requests\nimport random\nimport json\nimport logging\nimport uvicorn\n\napp = FastAPI()\n\n# Model endpoints\nMODEL_A_URL = "http://localhost:5000/invocations"  # Current model\nMODEL_B_URL = "http://localhost:5001/invocations"  # New model\n\n# Traffic split configuration\nTRAFFIC_SPLIT = {\n    "model_a": 0.8,  # 80% to current model\n    "model_b": 0.2,  # 20% to new model\n}\n\n\n@app.post("/predict")\nasync def predict(request: Request):\n    # Route traffic based on split\n    rand = random.random()\n\n    if rand < TRAFFIC_SPLIT["model_a"]:\n        endpoint = MODEL_A_URL\n        model_version = "A"\n    else:\n        endpoint = MODEL_B_URL\n        model_version = "B"\n\n    # Forward request\n    try:\n        req_json = await request.json()\n        response = requests.post(\n            endpoint,\n            headers={"Content-Type": "application/json"},\n            data=json.dumps(req_json),\n            timeout=30,\n        )\n\n        result = response.json()\n\n        # Log for analysis\n        logging.info(f"Model: {model_version}, Request: {req_json}, Response: {result}")\n\n        return JSONResponse(\n            content={"prediction": result, "model_version": model_version}\n        )\n\n    except Exception as e:\n        logging.error(f"Error with model {model_version}: {e}")\n        return JSONResponse(content={"error": str(e)}, status_code=500)\n\n\nif __name__ == "__main__":\n    uvicorn.run(app, host="0.0.0.0", port=8080)\n'})})]}),(0,o.jsxs)(s.A,{value:"multi-model-serving",label:"Multi-model Serving",children:[(0,o.jsx)(n.p,{children:"Serve multiple models from a single endpoint for ensemble predictions or\nmodel routing based on input characteristics."}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport pandas as pd\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nimport uvicorn\n\napp = FastAPI()\n\n# Load specialized models\nmodels = {\n    "fraud_detection": mlflow.pyfunc.load_model("models:/<fraud-model-id>"),\n    "recommendation": mlflow.pyfunc.load_model("models:/<recommendation-model-id>"),\n    "classification": mlflow.pyfunc.load_model("models:/<classification-model-id>"),\n}\n\n\ndef route_request(input_data):\n    """Route request to appropriate model based on input characteristics"""\n\n    # Example routing logic\n    if "transaction_amount" in input_data.columns:\n        return "fraud_detection"\n    elif "user_id" in input_data.columns and "item_id" in input_data.columns:\n        return "recommendation"\n    else:\n        return "classification"\n\n\n@app.post("/predict")\nasync def smart_predict(request: Request):\n    data = await request.json()\n    input_df = pd.DataFrame(data["data"], columns=data["columns"])\n\n    # Route to appropriate model\n    model_name = route_request(input_df)\n    model = models[model_name]\n\n    # Make prediction\n    prediction = model.predict(input_df)\n\n    return JSONResponse(\n        content={"model_used": model_name, "prediction": prediction.tolist()}\n    )\n\n\nif __name__ == "__main__":\n    uvicorn.run(app, host="0.0.0.0", port=5000)\n'})})]})]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Explore ",(0,o.jsx)(n.a,{href:"./custom-apps",children:"Custom Applications"})," to build advanced serving logic"]}),"\n",(0,o.jsxs)(n.li,{children:["Understand ",(0,o.jsx)(n.a,{href:"./responses-agent",children:"ResponsesAgent"})," for handling complex response patterns"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"For more detailed information about MLflow serving capabilities, refer to the official MLflow documentation and experiment with the examples provided in each section."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}}}]);